{"cells":[{"cell_type":"code","execution_count":1,"id":"1770e7db6b6f65d2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13924,"status":"ok","timestamp":1729615815371,"user":{"displayName":"Poppy Wang","userId":"05702602792977019287"},"user_tz":240},"id":"1770e7db6b6f65d2","outputId":"a33d72ac-bf29-4b09-db25-e8e61ba2edf7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["## Mount Google Drive Data\n","try:\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","except:\n","    print(\"Mounting Failed.\")"]},{"cell_type":"code","execution_count":null,"id":"173f2196f0a058c7","metadata":{"id":"173f2196f0a058c7"},"outputs":[],"source":["# ## Unzip files\n","# import tarfile\n","# tarfile_pth = '/content/drive/MyDrive/Capstone_code/Task02_Heart.tar'\n","# output_pth = '/content/drive/MyDrive/Capstone_code/Data'\n","# with tarfile.open(tarfile_pth, 'r') as tar:\n","#     tar.extractall(path=output_pth)"]},{"cell_type":"code","execution_count":2,"id":"f72078782f308fef","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5438,"status":"ok","timestamp":1729615863624,"user":{"displayName":"Poppy Wang","userId":"05702602792977019287"},"user_tz":240},"id":"f72078782f308fef","outputId":"57918dcf-0ba3-4efb-a8fa-94e6b11c6b24"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (24.1)\n","Collecting causal-conv1d\n","  Downloading causal_conv1d-1.4.0.tar.gz (9.3 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from causal-conv1d) (2.4.1+cu121)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from causal-conv1d) (24.1)\n","Collecting ninja (from causal-conv1d)\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch-\u003ecausal-conv1d) (3.16.1)\n","Requirement already satisfied: typing-extensions\u003e=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-\u003ecausal-conv1d) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-\u003ecausal-conv1d) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-\u003ecausal-conv1d) (3.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-\u003ecausal-conv1d) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-\u003ecausal-conv1d) (2024.6.1)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch-\u003ecausal-conv1d) (3.0.2)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch-\u003ecausal-conv1d) (1.3.0)\n","Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: causal-conv1d\n","  Building wheel for causal-conv1d (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for causal-conv1d: filename=causal_conv1d-1.4.0-cp310-cp310-linux_x86_64.whl size=104867883 sha256=b5e7cf7e964b5e99275d97ba1e1b0ee4e3073f4593743ba1f1c6aa394a3008cc\n","  Stored in directory: /root/.cache/pip/wheels/e3/dd/4c/205f24e151736bd22f5980738dd10a19af6f093b6f4dcab006\n","Successfully built causal-conv1d\n","Installing collected packages: ninja, causal-conv1d\n","Successfully installed causal-conv1d-1.4.0 ninja-1.11.1.1\n","Collecting mamba-ssm\n","  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.4.1+cu121)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (24.1)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (1.11.1.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (0.8.0)\n","Collecting triton (from mamba-ssm)\n","  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch-\u003emamba-ssm) (3.16.1)\n","Requirement already satisfied: typing-extensions\u003e=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-\u003emamba-ssm) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-\u003emamba-ssm) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-\u003emamba-ssm) (3.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-\u003emamba-ssm) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-\u003emamba-ssm) (2024.6.1)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers-\u003emamba-ssm) (0.24.7)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers-\u003emamba-ssm) (1.26.4)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers-\u003emamba-ssm) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers-\u003emamba-ssm) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers-\u003emamba-ssm) (2.32.3)\n","Requirement already satisfied: safetensors\u003e=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers-\u003emamba-ssm) (0.4.5)\n","Requirement already satisfied: tokenizers\u003c0.20,\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers-\u003emamba-ssm) (0.19.1)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers-\u003emamba-ssm) (4.66.5)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch-\u003emamba-ssm) (3.0.2)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers-\u003emamba-ssm) (3.4.0)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers-\u003emamba-ssm) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers-\u003emamba-ssm) (2.2.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers-\u003emamba-ssm) (2024.8.30)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch-\u003emamba-ssm) (1.3.0)\n","Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: mamba-ssm\n","  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.2-cp310-cp310-linux_x86_64.whl size=323988104 sha256=6b082468a6abb6f6bc50c99263f17c6c7f5a2e8f6b275ed7998b81fb25279229\n","  Stored in directory: /root/.cache/pip/wheels/57/7c/90/9f963468ecc3791e36e388f9e7b4a4e1e3f90fbb340055aa4d\n","Successfully built mamba-ssm\n","Installing collected packages: triton, mamba-ssm\n","Successfully installed mamba-ssm-2.2.2 triton-3.1.0\n","Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.11)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.1+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-\u003etimm) (3.16.1)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-\u003etimm) (2024.6.1)\n","Requirement already satisfied: packaging\u003e=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-\u003etimm) (24.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-\u003etimm) (2.32.3)\n","Requirement already satisfied: tqdm\u003e=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-\u003etimm) (4.66.5)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-\u003etimm) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-\u003etimm) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-\u003etimm) (3.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-\u003etimm) (3.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision-\u003etimm) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision-\u003etimm) (10.4.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch-\u003etimm) (3.0.2)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface_hub-\u003etimm) (3.4.0)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface_hub-\u003etimm) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface_hub-\u003etimm) (2.2.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface_hub-\u003etimm) (2024.8.30)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch-\u003etimm) (1.3.0)\n"]}],"source":["## Prepare Mamba environment\n","!pip install packaging\n","!pip install causal-conv1d\n","!pip install mamba-ssm\n","!pip install timm"]},{"cell_type":"code","execution_count":3,"id":"7817e73dee794604","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14416,"status":"ok","timestamp":1729615883781,"user":{"displayName":"Poppy Wang","userId":"05702602792977019287"},"user_tz":240},"id":"7817e73dee794604","outputId":"07a4f7ab-f3dd-4a8e-fe39-a2ec5b0caa17"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n","  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n","  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n","  def backward(ctx, dout):\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n","  def forward(\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n","  def backward(ctx, dout, *args):\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n","  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n","  def backward(ctx, grad_output):\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n","  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n","/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n","  def backward(ctx, dout, *args):\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import sys\n","import argparse\n","\n","sys.path.append('/content/drive/MyDrive/capstone_code/utils')\n","sys.path.append('/content/drive/MyDrive/capstone_code/models')\n","\n","from trainer import Trainer\n","from dataset import get_data, ImageDataset\n","from visualization import visualize_label\n","from visualization import visualize_prediction\n","from evaluation import evaluation\n","\n","import UNet, TransUnet, MambaUnet #, MambaUnet"]},{"cell_type":"code","execution_count":17,"id":"74b7fca874295537","metadata":{"executionInfo":{"elapsed":169,"status":"ok","timestamp":1729618820808,"user":{"displayName":"Poppy Wang","userId":"05702602792977019287"},"user_tz":240},"id":"74b7fca874295537"},"outputs":[],"source":["# 跑这个\n","parser = argparse.ArgumentParser(description='Training')\n","# Define path\n","parser.add_argument(\"--data_path\", type=str, default=\"/content/drive/MyDrive/capstone_code/Data/Task06_Lung\")\n","parser.add_argument(\"--model_path\", type=str, default=\"/content/drive/MyDrive/capstone_code/checkpoints\")\n","# Whether to continue training\n","parser.add_argument(\"--ct\", type=bool, default=False)\n","\n","# parser.add_argument(\"--model_name\", type=str, default=\"unet\")\n","# parser.add_argument(\"--model_name\", type=str, default=\"transunet\")\n","parser.add_argument(\"--model_name\", type=str, default=\"mambaunet\")\n","parser.add_argument(\"--num_classes\", type=int, default=2)\n","parser.add_argument(\"--n_skip\", type=int, default=3)\n","parser.add_argument(\"--num_epochs\", type=int, default=200)\n","# Define learning rate\n","parser.add_argument(\"--learning_rate\", type=int, default=0.001)\n","# Define batch size\n","parser.add_argument(\"--train_batch\", type=int, default=16)\n","parser.add_argument(\"--val_batch\", type=int, default=16)\n","parser.add_argument(\"--test_batch\", type=int, default=1)\n","args = parser.parse_args([])"]},{"cell_type":"code","execution_count":6,"id":"fzEsLBybVJaJ","metadata":{"executionInfo":{"elapsed":17447,"status":"ok","timestamp":1729615939164,"user":{"displayName":"Poppy Wang","userId":"05702602792977019287"},"user_tz":240},"id":"fzEsLBybVJaJ"},"outputs":[],"source":["import numpy as np\n","# Use only labeled data\n","# all_image, all_label = get_data(args.data_path, args.num_classes)\n","all_image = np.load('/content/drive/MyDrive/capstone_code/all_image.npy')\n","all_label = np.load('/content/drive/MyDrive/capstone_code/all_label.npy')"]},{"cell_type":"code","execution_count":8,"id":"eFb8wRQeVM1e","metadata":{"executionInfo":{"elapsed":1089,"status":"ok","timestamp":1729615962384,"user":{"displayName":"Poppy Wang","userId":"05702602792977019287"},"user_tz":240},"id":"eFb8wRQeVM1e"},"outputs":[],"source":["\n","# Training 80%\n","# Validation 10%\n","# Testing 10%\n","train_data, temp_data, train_label, temp_label = train_test_split(all_image, all_label, test_size=0.2, random_state=42)\n","val_data, test_data, val_label, test_label = train_test_split(temp_data, temp_label, test_size=0.5, random_state=42)\n","del all_image\n","del all_label"]},{"cell_type":"code","execution_count":9,"id":"8bb79f30d38fea7d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":173,"status":"ok","timestamp":1729615965552,"user":{"displayName":"Poppy Wang","userId":"05702602792977019287"},"user_tz":240},"id":"8bb79f30d38fea7d","outputId":"f86c5760-71fe-4c7b-d068-0ee7df770d8b"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2602, 224, 224)\n","(325, 224, 224)\n","(326, 224, 224)\n"]}],"source":["print(train_data.shape)\n","print(val_data.shape)\n","print(test_data.shape)"]},{"cell_type":"code","execution_count":10,"id":"f3ec85ab2ebf1da6","metadata":{"executionInfo":{"elapsed":160,"status":"ok","timestamp":1729615984733,"user":{"displayName":"Poppy Wang","userId":"05702602792977019287"},"user_tz":240},"id":"f3ec85ab2ebf1da6"},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomVerticalFlip(p=0.5),\n","    transforms.RandomRotation(10)\n","])"]},{"cell_type":"code","execution_count":11,"id":"9371018ef9aa13f3","metadata":{"executionInfo":{"elapsed":222,"status":"ok","timestamp":1729616004145,"user":{"displayName":"Poppy Wang","userId":"05702602792977019287"},"user_tz":240},"id":"9371018ef9aa13f3"},"outputs":[],"source":["train_dataset = ImageDataset(train_data, train_label, transform=transform)\n","val_dataset = ImageDataset(val_data, val_label)\n","test_dataset = ImageDataset(test_data, test_label)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=args.train_batch, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=args.val_batch, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=args.test_batch, shuffle=False)"]},{"cell_type":"code","execution_count":null,"id":"5e9a505faa6e9227","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"5e9a505faa6e9227"},"outputs":[{"name":"stdout","output_type":"stream","text":["Start Training mambaunet...\n","No checkpoint found to load.\n","\n","EPOCH 1 of 200\n","\n","training loss: 0.2586473464234475,\n","validation loss: 0.25090425709883374\n","\n","EPOCH 2 of 200\n","\n","training loss: 0.2141891590382424,\n","validation loss: 0.20242661308674587\n","\n","EPOCH 3 of 200\n","\n","training loss: 0.1676021668991428,\n","validation loss: 0.1660855064789454\n","\n","EPOCH 4 of 200\n","\n","training loss: 0.15256453120361077,\n","validation loss: 0.13568531455738203\n","\n","EPOCH 5 of 200\n","\n","training loss: 0.14717504162729883,\n","validation loss: 0.16307330167009718\n","\n","EPOCH 6 of 200\n","\n","training loss: 0.13376800087423413,\n","validation loss: 0.1272057458048775\n","\n","EPOCH 7 of 200\n","\n","training loss: 0.11988276368909818,\n","validation loss: 0.11425892121735073\n","\n","EPOCH 8 of 200\n","\n","training loss: 0.1179205998092707,\n","validation loss: 0.08334213158204443\n","\n","EPOCH 9 of 200\n","\n","training loss: 0.11490845453976853,\n","validation loss: 0.1236128592420192\n","\n","EPOCH 10 of 200\n","\n","training loss: 0.10719009289986517,\n","validation loss: 0.08398306334302538\n","\n","EPOCH 11 of 200\n","\n","training loss: 0.11387499531536746,\n","validation loss: 0.09664713112371308\n","\n","EPOCH 12 of 200\n","\n","training loss: 0.11097969649576701,\n","validation loss: 0.07304311632400468\n","\n","EPOCH 13 of 200\n","\n","training loss: 0.09561359323561192,\n","validation loss: 0.0786565871288379\n","\n","EPOCH 14 of 200\n","\n","training loss: 0.09373866939242997,\n","validation loss: 0.07494977772945449\n","\n","EPOCH 15 of 200\n","\n","training loss: 0.09032967247845937,\n","validation loss: 0.07296862293566976\n","\n","EPOCH 16 of 200\n","\n","training loss: 0.08215922358348692,\n","validation loss: 0.06888451586876597\n","\n","EPOCH 17 of 200\n","\n","training loss: 0.07740593375923809,\n","validation loss: 0.05208120974046843\n","\n","EPOCH 18 of 200\n","\n","training loss: 0.0771747937003162,\n","validation loss: 0.0703676561159747\n","\n","EPOCH 19 of 200\n","\n","training loss: 0.08052950415280333,\n","validation loss: 0.08571296220734007\n","\n","EPOCH 20 of 200\n","\n","training loss: 0.09279759835017605,\n","validation loss: 0.058408615755892936\n","\n","EPOCH 21 of 200\n","\n","training loss: 0.07683937601242329,\n","validation loss: 0.05518786476126739\n","\n","EPOCH 22 of 200\n","\n","training loss: 0.0714626009318909,\n","validation loss: 0.05964548885822296\n","\n","EPOCH 23 of 200\n","\n","training loss: 0.06997026400240652,\n","validation loss: 0.07401660705606143\n","\n","EPOCH 24 of 200\n","\n","training loss: 0.06971049290493223,\n","validation loss: 0.09935939329720679\n","\n","EPOCH 25 of 200\n","\n","training loss: 0.0763803014040359,\n","validation loss: 0.06644681575042861\n","\n","EPOCH 26 of 200\n","\n","training loss: 0.07301837375010449,\n","validation loss: 0.05751480632239864\n","\n","EPOCH 27 of 200\n","\n","training loss: 0.0627871143397378,\n","validation loss: 0.05114845221950894\n","\n","EPOCH 28 of 200\n","\n","training loss: 0.06667928483360018,\n","validation loss: 0.0700726830178783\n","\n","EPOCH 29 of 200\n","\n","training loss: 0.06793483281565224,\n","validation loss: 0.06116547683874766\n","\n","EPOCH 30 of 200\n","\n","training loss: 0.06748315117156213,\n","validation loss: 0.058629234631856285\n","\n","EPOCH 31 of 200\n","\n","training loss: 0.06380054375236752,\n","validation loss: 0.05061605528351806\n","\n","EPOCH 32 of 200\n","\n","training loss: 0.060881866119299195,\n","validation loss: 0.05070629148256211\n","\n","EPOCH 33 of 200\n","\n","training loss: 0.07609745902380695,\n","validation loss: 0.055615791430075966\n","\n","EPOCH 34 of 200\n","\n","training loss: 0.0658976090214918,\n","validation loss: 0.05126524503741946\n","\n","EPOCH 35 of 200\n","\n","training loss: 0.06526016955909554,\n","validation loss: 0.05716841366319429\n","\n","EPOCH 36 of 200\n","\n","training loss: 0.057042458957415415,\n","validation loss: 0.04510969659757046\n","\n","EPOCH 37 of 200\n","\n","training loss: 0.056321785905244164,\n","validation loss: 0.04376953210504282\n","\n","EPOCH 38 of 200\n","\n","training loss: 0.06152512766763659,\n","validation loss: 0.07256224946606726\n","\n","EPOCH 39 of 200\n","\n","training loss: 0.06406208403134273,\n","validation loss: 0.06328830930093925\n","\n","EPOCH 40 of 200\n","\n","training loss: 0.05728660141649239,\n","validation loss: 0.049566898051471936\n","\n","EPOCH 41 of 200\n","\n","training loss: 0.05265300590659212,\n","validation loss: 0.054182984289668855\n","\n","EPOCH 42 of 200\n","\n","training loss: 0.05865884198024412,\n","validation loss: 0.045244247785636356\n","\n","EPOCH 43 of 200\n","\n","training loss: 0.0604475862089476,\n","validation loss: 0.05337588648710932\n","\n","EPOCH 44 of 200\n","\n","training loss: 0.05631541320197056,\n","validation loss: 0.05147165255177589\n","\n","EPOCH 45 of 200\n","\n","training loss: 0.05905500949114744,\n","validation loss: 0.05771652068055812\n","\n","EPOCH 46 of 200\n","\n","training loss: 0.048198215263478596,\n","validation loss: 0.049804730606930595\n","\n","EPOCH 47 of 200\n","\n","training loss: 0.05048910512423223,\n","validation loss: 0.043163507555921875\n","\n","EPOCH 48 of 200\n","\n","training loss: 0.04826862002762915,\n","validation loss: 0.04857204109430313\n","\n","EPOCH 49 of 200\n","\n","training loss: 0.052085614266114,\n","validation loss: 0.040676179475017955\n","\n","EPOCH 50 of 200\n","\n","training loss: 0.04895463257890903,\n","validation loss: 0.04166750769530024\n","\n","EPOCH 51 of 200\n","\n","training loss: 0.05574591123024745,\n","validation loss: 0.04945019464052859\n","\n","EPOCH 52 of 200\n","\n","training loss: 0.05419823111954825,\n","validation loss: 0.04494336850586392\n","\n","EPOCH 53 of 200\n","\n","training loss: 0.05434304611768825,\n","validation loss: 0.04482457201395716\n","\n","EPOCH 54 of 200\n","\n","training loss: 0.04774656712414663,\n","validation loss: 0.04698647682865461\n","\n","EPOCH 55 of 200\n","\n","training loss: 0.046643585469459466,\n","validation loss: 0.041796195276436354\n","\n","EPOCH 56 of 200\n","\n","training loss: 0.049825198314169795,\n","validation loss: 0.04774832494911693\n","\n","EPOCH 57 of 200\n","\n","training loss: 0.05740068696347848,\n","validation loss: 0.05038623245699065\n","\n","EPOCH 58 of 200\n","\n","training loss: 0.05000377606394832,\n","validation loss: 0.048352738576275964\n","\n","EPOCH 59 of 200\n","\n","training loss: 0.051520250143449,\n","validation loss: 0.03850956793342318\n","\n","EPOCH 60 of 200\n","\n","training loss: 0.04374068831464996,\n","validation loss: 0.03668685860577084\n","\n","EPOCH 61 of 200\n","\n","training loss: 0.04374143259565523,\n","validation loss: 0.035296818951056116\n","\n","EPOCH 62 of 200\n","\n","training loss: 0.043652318103776025,\n","validation loss: 0.043154913488598096\n","\n","EPOCH 63 of 200\n","\n","training loss: 0.045068461522231436,\n","validation loss: 0.03748495708264056\n","\n","EPOCH 64 of 200\n","\n","training loss: 0.04263357357607663,\n","validation loss: 0.0476120470889977\n","\n","EPOCH 65 of 200\n","\n","training loss: 0.04821750380533056,\n","validation loss: 0.039819885932263877\n","\n","EPOCH 66 of 200\n","\n","training loss: 0.049099239475019506,\n","validation loss: 0.03733109496533871\n","\n","EPOCH 67 of 200\n","\n","training loss: 0.05010900664160405,\n","validation loss: 0.037268138357571194\n","\n","EPOCH 68 of 200\n","\n","training loss: 0.04544972650638204,\n","validation loss: 0.03214843234135991\n","\n","EPOCH 69 of 200\n","\n","training loss: 0.04663609936147745,\n","validation loss: 0.03582006577579748\n","\n","EPOCH 70 of 200\n","\n","training loss: 0.04168041069860473,\n","validation loss: 0.041679821110197475\n","\n","EPOCH 71 of 200\n","\n","training loss: 0.042918936058056134,\n","validation loss: 0.03752273090538524\n","\n","EPOCH 72 of 200\n","\n","training loss: 0.03963185492560176,\n","validation loss: 0.04124175792648679\n","\n","EPOCH 73 of 200\n","\n","training loss: 0.04027428448291644,\n","validation loss: 0.03665233394574551\n","\n","EPOCH 74 of 200\n","\n","training loss: 0.03953895559591567,\n","validation loss: 0.035869344181957696\n","\n","EPOCH 75 of 200\n","\n","training loss: 0.04725569028955844,\n","validation loss: 0.03710895696921008\n","\n","EPOCH 76 of 200\n","\n","training loss: 0.038406867648194905,\n","validation loss: 0.03713964409239236\n","\n","EPOCH 77 of 200\n","\n","training loss: 0.04275870340893422,\n","validation loss: 0.03984440623649529\n","\n","EPOCH 78 of 200\n","\n","training loss: 0.04227015706910495,\n","validation loss: 0.03891499305055255\n","Early stop due to validation loss not decrease for 10 epochs\n"]}],"source":["#然后跑这个\n","if args.model_name in [\"unet\", \"transunet\", \"mambaunet\"]:\n","    if args.model_name == \"unet\":\n","        model = UNet.UNet(args.num_classes)\n","    elif args.model_name == \"transunet\":\n","        model = TransUnet.TransUnet(args.num_classes, args.n_skip)\n","    else:\n","        model = MambaUnet.MambaUnet(args.num_classes)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.num_epochs, eta_min=0.00001)\n","    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, min_lr=1e-6)\n","\n","    trainer = Trainer(args)\n","    trainer.train(model, optimizer, scheduler, train_dataloader, val_dataloader)\n","else:\n","    print(\"Wrong model type!\")"]},{"cell_type":"code","execution_count":null,"id":"c295a2a786c9edeb","metadata":{"id":"c295a2a786c9edeb"},"outputs":[],"source":["if args.model_name in [\"unet\", \"transunet\", \"mambaunet\"]:\n","    if args.model_name == \"unet\":\n","        model = UNet.UNet(args.num_classes)\n","        df_unet = evaluation(args, model, test_dataloader)\n","    elif args.model_name == \"transunet\":\n","        model = TransUnet.TransUnet(args.num_classes, args.n_skip)\n","        df_trans = evaluation(args, model, test_dataloader)\n","    else:\n","        model = MambaUnet.MambaUnet(args.num_classes)\n","        df_mamba = evaluation(args, model, test_dataloader)\n","\n","else:\n","    print(\"Wrong model type!\")"]},{"cell_type":"code","execution_count":null,"id":"jkH-aqFjVg-l","metadata":{"id":"jkH-aqFjVg-l"},"outputs":[],"source":["import os\n","import pandas as pd\n","excel_path = os.path.join(args.model_path, \"network_comparison_10_22.xlsx\")\n","with pd.ExcelWriter(excel_path) as writer:\n","    df_unet.to_excel(writer, sheet_name=\"U-Net\", index=False)\n","    df_trans.to_excel(writer, sheet_name=\"TransUNet\", index=False)\n","    df_mamba.to_excel(writer, sheet_name=\"MambaUnet\", index=False)"]},{"cell_type":"code","execution_count":null,"id":"WEigpBI1R-iQ","metadata":{"id":"WEigpBI1R-iQ"},"outputs":[],"source":["import os\n","os._exit(00)"]},{"cell_type":"code","execution_count":null,"id":"2aGhhqRLWB8F","metadata":{"id":"2aGhhqRLWB8F"},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","# idx = 90\n","# sample = test_dataset[idx]\n","# sample_image = sample[\"data\"].squeeze()\n","# sample_label = sample[\"label\"]\n","# model = MambaUnet.MambaUnet(args.num_classes)\n","# plt.imshow(visualize_prediction(args, sample_image, model))\n","# plt.axis(\"off\")\n","# plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":5}